{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9gyYqXxn3Fgj"
   },
   "source": [
    "# pandas with Excel files and seaborn\n",
    "\n",
    "In this session, you will be working with data contained in a spreadsheet. The file, named `Test_RR_TnTx_data.xlsx` contains three (3) separate sheets of Rainfall, Minimum Temperature and Maximum Temperature from the Ghana Meteorological Agency (GMet). The data is an *in situ* observation with a short term temporal span intended for the Python education. Kindly note that the acquired data must serve only the educational purpose intended.\n",
    "\n",
    "We'll also be seeing how to use `seaborn` to produce useful plots for studying correlations and relationships in the observations. And we'll be using the `pymannkendall` package which implements the Mann-Kendall method for finding trends in the observations.\n",
    "\n",
    "**Objectives** \n",
    "\n",
    "The following objectives are outlined for this lesson. Participants, at the end of the lesson should have adequate knowledge in the following:\n",
    "\n",
    "1.\tLoading data from an excel spreadsheet using Pandas, and some basic pandas features/ functionalities.\n",
    "2.\tWorking with timeseries data\n",
    "3.\tStacking Data using a defined function\n",
    "4.\tData slicing, Groupby, etc\n",
    "5.\tSimple Computations and Data Description (sum, mean, percentiles)\n",
    "6.\tMoving Averages / Rolling Windows\n",
    "7.\tQuantifying trends\n",
    "8.\tExtreme Indices (Rnnmm, percentile differences)\n",
    "9.\tVisualization with seaborn\n",
    "\n",
    "\n",
    "\n",
    "***Let's start by importing relevant packages.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "j4l1G20As4P4"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"import pandas as pd\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nimport seaborn as sb  # Useful for artistic and more scientific data visualization\\nimport pymannkendall as mk  # Useful Python package for identifying Mann-Kendall trends in a dataset.\\nimport calendar  # We need the calendar package to generate certain calendar properties\\nfrom datetime import datetime\\nfrom dateutil import parser\\nfrom pathlib import Path\";\n",
       "                var nbb_formatted_code = \"import pandas as pd\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nimport seaborn as sb  # Useful for artistic and more scientific data visualization\\nimport pymannkendall as mk  # Useful Python package for identifying Mann-Kendall trends in a dataset.\\nimport calendar  # We need the calendar package to generate certain calendar properties\\nfrom datetime import datetime\\nfrom dateutil import parser\\nfrom pathlib import Path\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb  # Useful for artistic and more scientific data visualization\n",
    "import pymannkendall as mk  # Useful Python package for identifying Mann-Kendall trends in a dataset.\n",
    "import calendar  # We need the calendar package to generate certain calendar properties\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"data_path = Path(\\\"../data\\\")\";\n",
       "                var nbb_formatted_code = \"data_path = Path(\\\"../data\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_path = Path(\"../data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1OT4VGi83h2"
   },
   "source": [
    "## 1. Loading data from `.xlsx` Excel spreadsheet file\n",
    "\n",
    "We'll now read in the rainfall and temperature data from different sheets in a single `.xslx` Excel spreadsheet file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the `xlrd` package (which `pandas` used to use for reading `.xslx`-files [recently removed support for `.xslx`-files](https://stackoverflow.com/a/65266270/271776)). Fortunately `pandas` can use `openpyxl` instead, but unless you pandas version `>=1.2.0` you will have to tell `pandas` to use `openpyxl` using the `engine='openpyxl'` argument when opening a file.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sheet **RR** contains Daily Rainfall Totals, sheet **Tn** contains Daily Minimum Temperature and **Tx** contains the Daily Maximum Temperature data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "iG_yA2u6s4P6"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"filepath_spreadsheet = data_path / \\\"Test_RR_TnTx_data.xlsx\\\"\\n# Rainfall\\nRR = pd.read_excel(filepath_spreadsheet, sheet_name=\\\"RR\\\", engine=\\\"openpyxl\\\")\\n# Minimum Temperature\\nTN = pd.read_excel(filepath_spreadsheet, sheet_name=\\\"Tn\\\", engine=\\\"openpyxl\\\")\\n# Maximum Temperature\\nTX = pd.read_excel(filepath_spreadsheet, sheet_name=\\\"Tx\\\", engine=\\\"openpyxl\\\")\";\n",
       "                var nbb_formatted_code = \"filepath_spreadsheet = data_path / \\\"Test_RR_TnTx_data.xlsx\\\"\\n# Rainfall\\nRR = pd.read_excel(filepath_spreadsheet, sheet_name=\\\"RR\\\", engine=\\\"openpyxl\\\")\\n# Minimum Temperature\\nTN = pd.read_excel(filepath_spreadsheet, sheet_name=\\\"Tn\\\", engine=\\\"openpyxl\\\")\\n# Maximum Temperature\\nTX = pd.read_excel(filepath_spreadsheet, sheet_name=\\\"Tx\\\", engine=\\\"openpyxl\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filepath_spreadsheet = data_path / \"Test_RR_TnTx_data.xlsx\"\n",
    "# Rainfall\n",
    "RR = pd.read_excel(filepath_spreadsheet, sheet_name=\"RR\", engine=\"openpyxl\")\n",
    "# Minimum Temperature\n",
    "TN = pd.read_excel(filepath_spreadsheet, sheet_name=\"Tn\", engine=\"openpyxl\")\n",
    "# Maximum Temperature\n",
    "TX = pd.read_excel(filepath_spreadsheet, sheet_name=\"Tx\", engine=\"openpyxl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each sheet, the data is stored as:\n",
    "\n",
    "- **Column A :** the Station Name (for 3 stations, namely: Tamale, Kumasi and Tema).\n",
    "- **Column B :** abbreviation of parameter of interest (eg. RR for rainfall)\n",
    "- **Column C :** Year of observation\n",
    "- **Column D :** Month of observation\n",
    "- **Columns E to AI :** Daily Data (Day 1 to maximum days in the month. Eg. Columns E to AI on the second rows contains data for 1st to 31st January 2010)\n",
    "\n",
    "The first row contains the headers of each column and `pandas` uses this to set the column names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the first few rows of the loaded rainfall data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "BCUjKYORs4P7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Eg El Abbreviation</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Val01</th>\n",
       "      <th>Val02</th>\n",
       "      <th>Val03</th>\n",
       "      <th>Val04</th>\n",
       "      <th>Val05</th>\n",
       "      <th>Val06</th>\n",
       "      <th>...</th>\n",
       "      <th>Val22</th>\n",
       "      <th>Val23</th>\n",
       "      <th>Val24</th>\n",
       "      <th>Val25</th>\n",
       "      <th>Val26</th>\n",
       "      <th>Val27</th>\n",
       "      <th>Val28</th>\n",
       "      <th>Val29</th>\n",
       "      <th>Val30</th>\n",
       "      <th>Val31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tamale</td>\n",
       "      <td>RR</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tamale</td>\n",
       "      <td>RR</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tamale</td>\n",
       "      <td>RR</td>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tamale</td>\n",
       "      <td>RR</td>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>89.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tamale</td>\n",
       "      <td>RR</td>\n",
       "      <td>2010</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name Eg El Abbreviation  Year  Month  Val01  Val02  Val03  Val04  Val05  \\\n",
       "0  Tamale                 RR  2010      1    0.0    0.0    0.0    0.0    0.0   \n",
       "1  Tamale                 RR  2010      2    0.0    0.0    0.0    0.0    0.0   \n",
       "2  Tamale                 RR  2010      3    0.0    0.0    0.0    0.0    0.0   \n",
       "3  Tamale                 RR  2010      4    0.0    0.0    0.0    0.0    0.9   \n",
       "4  Tamale                 RR  2010      5    0.0    0.0    0.0    0.0    1.0   \n",
       "\n",
       "   Val06  ...  Val22  Val23  Val24  Val25  Val26  Val27  Val28  Val29  Val30  \\\n",
       "0    0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1    0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    NaN    NaN   \n",
       "2    0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3    0.0  ...   89.1    0.0    0.0    0.0   73.3    1.5    0.0    0.0    0.0   \n",
       "4    0.0  ...    0.0    0.5    0.0    0.0    0.0    0.0    0.0    4.5    0.0   \n",
       "\n",
       "   Val31  \n",
       "0    0.0  \n",
       "1    NaN  \n",
       "2    0.0  \n",
       "3    NaN  \n",
       "4    0.6  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"RR.head()  # Shows the first five rows of the data\";\n",
       "                var nbb_formatted_code = \"RR.head()  # Shows the first five rows of the data\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RR.head()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GaS-HYLo9TjN"
   },
   "source": [
    "We set the day number as column headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Rnvali7Ls4P-"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"RR.columns.values[4:] = np.arange(1, 32).astype(\\\"str\\\")\\nTN.columns.values[4:] = np.arange(1, 32).astype(\\\"str\\\")\\nTX.columns.values[4:] = np.arange(1, 32).astype(\\\"str\\\")\";\n",
       "                var nbb_formatted_code = \"RR.columns.values[4:] = np.arange(1, 32).astype(\\\"str\\\")\\nTN.columns.values[4:] = np.arange(1, 32).astype(\\\"str\\\")\\nTX.columns.values[4:] = np.arange(1, 32).astype(\\\"str\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RR.columns.values[4:] = np.arange(1, 32).astype(\"str\")\n",
    "TN.columns.values[4:] = np.arange(1, 32).astype(\"str\")\n",
    "TX.columns.values[4:] = np.arange(1, 32).astype(\"str\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lUN9XT_q9jOc"
   },
   "source": [
    "In the next part, we select only the columns containing the year, month and daily data. We will be vertically stacking these using a defined function. In the end, the datasets should look somewhat like this:\n",
    "\n",
    "19800101  RR1 <br>\n",
    "19800102  RR2 <br>\n",
    "... <br>\n",
    "... <br>\n",
    "... <br>\n",
    "20201231 RRN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "KmqTKW10s4P_",
    "outputId": "be6b646d-4077-46b3-8111-1b73a6ff776d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Month    1    2    3    4    5    6    7    8  ...   22   23   24  \\\n",
       "0  2010      1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "1  2010      2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "    25   26   27   28   29   30   31  \n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  NaN  NaN  NaN  \n",
       "\n",
       "[2 rows x 33 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"RR2s = RR.iloc[:, 2:]\\nTN2s = TN.iloc[:, 2:]\\nTX2s = TX.iloc[:, 2:]\\nRR2s.head(2)\";\n",
       "                var nbb_formatted_code = \"RR2s = RR.iloc[:, 2:]\\nTN2s = TN.iloc[:, 2:]\\nTX2s = TX.iloc[:, 2:]\\nRR2s.head(2)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RR2s = RR.iloc[:, 2:]\n",
    "TN2s = TN.iloc[:, 2:]\n",
    "TX2s = TX.iloc[:, 2:]\n",
    "RR2s.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LlfB0Hm1s4QA"
   },
   "source": [
    "---------------------------------------------------------------------------------------------------------------------------------\n",
    "Wrangling the data\n",
    "---------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "**What is Data Wrangling?**\n",
    "\n",
    "Data wrangling is the process of cleaning, structuring and enriching raw data into a desired format for better decision making in less time. Data wrangling is increasingly ubiquitous. In simpler terms, data wrangling (sometimes referred to as data munging) entails transforming and mapping data from one \"raw\" data form into another format with the intent of making it more appropriate and valuable for a variety of downstream purposes such as analytics. \n",
    "Data has become more diverse and unstructured, demanding increased time spent culling, cleaning, and organizing data ahead of broader analysis. <br>\n",
    "\n",
    "**Reference:** <br>\n",
    "> https://www.trifacta.com/data-wrangling/ <br>\n",
    "> https://en.wikipedia.org/wiki/Data_wrangling <br><br><br>\n",
    "\n",
    "\n",
    "\n",
    "With this premise established, we will wrangle the rainfall/temperature data, and this will be addressed as such.\n",
    "\n",
    "> Vertically stacking the data using a DateTime index <br>\n",
    "> Basic manipulation and dealing with missing values <br>\n",
    "> Resampling to a different frequency\n",
    "---------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "gmTbL_pQs4QB"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"# Let generate a new dataframe with index for each day within the observation period.\\n# We begin with the date creation using pandas date_range function\\n\\n# Default frequency is daily\\ndate = pd.date_range(start=\\\"1/1/2010\\\", end=\\\"31/12/2013\\\", freq=\\\"D\\\")\\ntype(date)  ### returns pandas.core.indexes.datetimes.DatetimeIndex\\n\\n# Next, we populate a new dataframe with the actual data\\nNewRRData = pd.DataFrame(date, columns=[\\\"date\\\"])\\nNewTNData = pd.DataFrame(date, columns=[\\\"date\\\"])\\nNewTXData = pd.DataFrame(date, columns=[\\\"date\\\"])\\n\\n# Set the date as index of the new DataFrame.\\nNewRRData.set_index(\\\"date\\\", inplace=True)\\nNewTNData.set_index(\\\"date\\\", inplace=True)\\nNewTXData.set_index(\\\"date\\\", inplace=True)\";\n",
       "                var nbb_formatted_code = \"# Let generate a new dataframe with index for each day within the observation period.\\n# We begin with the date creation using pandas date_range function\\n\\n# Default frequency is daily\\ndate = pd.date_range(start=\\\"1/1/2010\\\", end=\\\"31/12/2013\\\", freq=\\\"D\\\")\\ntype(date)  ### returns pandas.core.indexes.datetimes.DatetimeIndex\\n\\n# Next, we populate a new dataframe with the actual data\\nNewRRData = pd.DataFrame(date, columns=[\\\"date\\\"])\\nNewTNData = pd.DataFrame(date, columns=[\\\"date\\\"])\\nNewTXData = pd.DataFrame(date, columns=[\\\"date\\\"])\\n\\n# Set the date as index of the new DataFrame.\\nNewRRData.set_index(\\\"date\\\", inplace=True)\\nNewTNData.set_index(\\\"date\\\", inplace=True)\\nNewTXData.set_index(\\\"date\\\", inplace=True)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let generate a new dataframe with index for each day within the observation period.\n",
    "# We begin with the date creation using pandas date_range function\n",
    "\n",
    "# Default frequency is daily\n",
    "date = pd.date_range(start=\"1/1/2010\", end=\"31/12/2013\", freq=\"D\")\n",
    "type(date)  ### returns pandas.core.indexes.datetimes.DatetimeIndex\n",
    "\n",
    "# Next, we populate a new dataframe with the actual data\n",
    "NewRRData = pd.DataFrame(date, columns=[\"date\"])\n",
    "NewTNData = pd.DataFrame(date, columns=[\"date\"])\n",
    "NewTXData = pd.DataFrame(date, columns=[\"date\"])\n",
    "\n",
    "# Set the date as index of the new DataFrame.\n",
    "NewRRData.set_index(\"date\", inplace=True)\n",
    "NewTNData.set_index(\"date\", inplace=True)\n",
    "NewTXData.set_index(\"date\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "cECTd2pvs4QC"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-01</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-03</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-04</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [2010-01-01 00:00:00, 2010-01-02 00:00:00, 2010-01-03 00:00:00, 2010-01-04 00:00:00, 2010-01-05 00:00:00]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"NewRRData.head()\";\n",
       "                var nbb_formatted_code = \"NewRRData.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "NewRRData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tDIWIF9R_SMk"
   },
   "source": [
    "Here, we will code a function that will help to transform the data in a column data timeseries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "UZDm3Ymus4QD"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"# Self-defined function to stack row-oriented data as columnar\\ndef data_stacking(d, Data, s):\\n    year = np.int_(d[\\\"Year\\\"])  # Format years as integers\\n    month = np.int_(d[\\\"Month\\\"])  # Format months as integers\\n\\n    # Let's create a blank column for the given station (s) which allows for appending data.\\n    Data[s] = None\\n\\n    for i in d.index:\\n        # Looping through the years and month and producing the total number of days in each month of the year.\\n        # We employ calendar.monthrange() to acquire the total number of days in a given month.\\n        # Within the datasets, there are 31 column for each month data. By specifying the total number of actual days in a month, we omit the excess NaNs\\n        # in the end when matching data from the existing data set to the new vertically stacked data, using the dates as reference index.\\n        total_days = calendar.monthrange(\\n            datetime.strptime(str(year[i]), \\\"%Y\\\").year,\\n            datetime.strptime(str(month[i]), \\\"%m\\\").month,\\n        )[1]\\n\\n        for day in range(\\n            1, total_days + 1\\n        ):  # for months with n days, we create a range of 1 to n+1 days to produce the exact n days. (eg. range(1,32) produces days 1 to 31)\\n            date_index = datetime.date(\\n                datetime.strptime(f\\\"{year[i]} {month[i]} {day}\\\", \\\"%Y %m %d\\\")\\n            )\\n\\n            # Populating the new data with exact data from the old set for the same day.\\n            Data[s].loc[date_index] = d.iloc[i, day + 1]\\n\\n    return Data  # return the stacked Data\";\n",
       "                var nbb_formatted_code = \"# Self-defined function to stack row-oriented data as columnar\\ndef data_stacking(d, Data, s):\\n    year = np.int_(d[\\\"Year\\\"])  # Format years as integers\\n    month = np.int_(d[\\\"Month\\\"])  # Format months as integers\\n\\n    # Let's create a blank column for the given station (s) which allows for appending data.\\n    Data[s] = None\\n\\n    for i in d.index:\\n        # Looping through the years and month and producing the total number of days in each month of the year.\\n        # We employ calendar.monthrange() to acquire the total number of days in a given month.\\n        # Within the datasets, there are 31 column for each month data. By specifying the total number of actual days in a month, we omit the excess NaNs\\n        # in the end when matching data from the existing data set to the new vertically stacked data, using the dates as reference index.\\n        total_days = calendar.monthrange(\\n            datetime.strptime(str(year[i]), \\\"%Y\\\").year,\\n            datetime.strptime(str(month[i]), \\\"%m\\\").month,\\n        )[1]\\n\\n        for day in range(\\n            1, total_days + 1\\n        ):  # for months with n days, we create a range of 1 to n+1 days to produce the exact n days. (eg. range(1,32) produces days 1 to 31)\\n            date_index = datetime.date(\\n                datetime.strptime(f\\\"{year[i]} {month[i]} {day}\\\", \\\"%Y %m %d\\\")\\n            )\\n\\n            # Populating the new data with exact data from the old set for the same day.\\n            Data[s].loc[date_index] = d.iloc[i, day + 1]\\n\\n    return Data  # return the stacked Data\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Self-defined function to stack row-oriented data as columnar\n",
    "def data_stacking(d, Data, s):\n",
    "    year = np.int_(d[\"Year\"])  # Format years as integers\n",
    "    month = np.int_(d[\"Month\"])  # Format months as integers\n",
    "\n",
    "    # Let's create a blank column for the given station (s) which allows for appending data.\n",
    "    Data[s] = None\n",
    "\n",
    "    for i in d.index:\n",
    "        # Looping through the years and month and producing the total number of days in each month of the year.\n",
    "        # We employ calendar.monthrange() to acquire the total number of days in a given month.\n",
    "        # Within the datasets, there are 31 column for each month data. By specifying the total number of actual days in a month, we omit the excess NaNs\n",
    "        # in the end when matching data from the existing data set to the new vertically stacked data, using the dates as reference index.\n",
    "        total_days = calendar.monthrange(\n",
    "            datetime.strptime(str(year[i]), \"%Y\").year,\n",
    "            datetime.strptime(str(month[i]), \"%m\").month,\n",
    "        )[1]\n",
    "\n",
    "        for day in range(\n",
    "            1, total_days + 1\n",
    "        ):  # for months with n days, we create a range of 1 to n+1 days to produce the exact n days. (eg. range(1,32) produces days 1 to 31)\n",
    "            date_index = datetime.date(\n",
    "                datetime.strptime(f\"{year[i]} {month[i]} {day}\", \"%Y %m %d\")\n",
    "            )\n",
    "\n",
    "            # Populating the new data with exact data from the old set for the same day.\n",
    "            Data[s].loc[date_index] = d.iloc[i, day + 1]\n",
    "\n",
    "    return Data  # return the stacked Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Oun_GNds4QE"
   },
   "source": [
    "#Start with one station and then move to multiples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "-JboWanls4QG"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"# Selecting Data for only one station\\nd = RR2s.where(RR.Name == \\\"Tema\\\")\\n\\n# Remove all the other rows where the year column contains NaNs. This will omit all other stations except Tema.\\nd = d[d[\\\"Year\\\"].notna()]\";\n",
       "                var nbb_formatted_code = \"# Selecting Data for only one station\\nd = RR2s.where(RR.Name == \\\"Tema\\\")\\n\\n# Remove all the other rows where the year column contains NaNs. This will omit all other stations except Tema.\\nd = d[d[\\\"Year\\\"].notna()]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Selecting Data for only one station\n",
    "d = RR2s.where(RR.Name == \"Tema\")\n",
    "\n",
    "# Remove all the other rows where the year column contains NaNs. This will omit all other stations except Tema.\n",
    "d = d[d[\"Year\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((48, 33), (1461, 1))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"d.shape, NewRRData.shape\";\n",
       "                var nbb_formatted_code = \"d.shape, NewRRData.shape\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d.shape, NewRRData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Q6p0ECM3s4QG",
    "outputId": "b2fefb3e-4ca2-4853-8816-bb7031671fdd"
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 96 is out of bounds for axis 0 with size 48",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-76731f849661>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Single Station (Data Stacking via self-defined function)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mNewRRData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_stacking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNewRRData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Tema\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mNewRRData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-aef62e9ea78a>\u001b[0m in \u001b[0;36mdata_stacking\u001b[0;34m(d, Data, s)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# in the end when matching data from the existing data set to the new vertically stacked data, using the dates as reference index.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         total_days = calendar.monthrange(\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"%Y\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonth\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"%m\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         )[1]\n",
      "\u001b[0;31mIndexError\u001b[0m: index 96 is out of bounds for axis 0 with size 48"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"# Single Station (Data Stacking via self-defined function)\\nNewRRData = data_stacking(d, NewRRData, \\\"Tema\\\")\\nNewRRData.head(2)\";\n",
       "                var nbb_formatted_code = \"# Single Station (Data Stacking via self-defined function)\\nNewRRData = data_stacking(d, NewRRData, \\\"Tema\\\")\\nNewRRData.head(2)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Single Station (Data Stacking via self-defined function)\n",
    "NewRRData = data_stacking(d, NewRRData, \"Tema\")\n",
    "NewRRData.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "myoZuEbEBgDC"
   },
   "source": [
    "We attempt to loop through all the given stations and stack them to the new dataframe. To generate the list of stations without duplicates, we simply use the set() function which produce a set of any identified list without duplicates. We then pass it as a list to allow us loop through them easily, while stacking to the defined dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZB1svlxBs4QH",
    "outputId": "ed50a0be-7d68-466d-db03-df7706d2c534"
   },
   "outputs": [],
   "source": [
    "#Creating Multiple columns for different stations\n",
    "stations=sorted(list(set(RR.Name)))\n",
    "for s in stations:\n",
    "    d = RR2s.where(RR.Name==s)\n",
    "    d = d[d['Year'].notna()]\n",
    "    # for multi station data, we reset the index to start from 0 to the total rows per station data.\n",
    "    d.index = range(len(d.index)) \n",
    "    NewRRData = data_stacking(d, NewRRData, s)\n",
    "\n",
    "NewRRData.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YGDqo8rns4QI"
   },
   "source": [
    "Can we recreate the stacked data for the minimum and maximum temperature data too?\n",
    "----------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tj1iL_IUs4QI"
   },
   "outputs": [],
   "source": [
    "stations=sorted(list(set(RR.Name)))\n",
    "for s in stations:\n",
    "    d=TN2s.where(TN.Name==s)\n",
    "    d = d[d['Year'].notna()]\n",
    "    # for multi station data, we reset the index to start from 0 to the total rows per station data.\n",
    "    d.index=range(len(d.index)) \n",
    "    NewTNData=data_stacking(d, NewTNData, s)\n",
    "    \n",
    "    d=TX2s.where(TX.Name==s)\n",
    "    d = d[d['Year'].notna()]\n",
    "    # for multi station data, we reset the index to start from 0 to the total rows per station data.\n",
    "    d.index=range(len(d.index)) \n",
    "    NewTXData=data_stacking(d, NewTXData, s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jk1dB70NDENm"
   },
   "source": [
    "In the next phase, we will perform data visualization with seaborn. <br >\n",
    "\n",
    "Seaborn is a Python data visualization library based on matplotlib **(https://seaborn.pydata.org/)**. It provides a high-level interface for drawing attractive and informative statistical graphics.<br>\n",
    "\n",
    "**Installation**<br>\n",
    "Official releases of seaborn can be installed from PyPI using:\n",
    "\n",
    "> **pip install seaborn**\n",
    "\n",
    "Alternatively, you can install via the Anaconda distribution using:\n",
    "\n",
    "> **conda install seaborn**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kjCAFrZCEFyr"
   },
   "source": [
    "KDE Plot\n",
    "----------------------------\n",
    "\n",
    "Let's start off with data distribution plots using Seaborn's Kernel Density Estimates (KDE), which is a method for estimating the underlying distribution that data is sampled from by smoothing the sampled using a Gaussian kernel. KDE represents the data using a continuous probability density curve in one or more dimensions. There are other ways of estimating the distribution. <br>\n",
    "\n",
    "Seaborn allows us to visualize the distribution of these observations, analagous to a histogram. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J_N2Zuqhs4QK",
    "outputId": "97043760-4c6b-490b-d9ac-c2756716e2ab"
   },
   "outputs": [],
   "source": [
    "#### Sample Seaborn Visualizations\n",
    "sb.kdeplot(NewRRData['Kumasi'].astype(float), legend=True, shade=True)   #Distribution plot\n",
    "sb.kdeplot(NewRRData['Tema'].astype(float), legend=True, shade=True)   #Distribution plot\n",
    "\n",
    "plt.legend(title='Stations', loc='upper right', labels=['Kumasi', 'Tema'])\n",
    "plt.xlabel('Rainfall (mm)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fZSGTktIEmSv"
   },
   "source": [
    "Scatter Plot\n",
    "----------------------------\n",
    "Scatter plots represent values for two different numeric variables. Scatter plots are used to observe relationships between the two variables.\n",
    "\n",
    "> Let's attempt to see if there's a synergy in the rainfall events in any two locations (eg. Kumasi and Tema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zGjmOAu1s4QK",
    "outputId": "4b7676cf-a272-4fdd-80d3-b4ed86bf7cb6"
   },
   "outputs": [],
   "source": [
    "sb.scatterplot(y='Kumasi', x='Tema', data=NewRRData)\n",
    "plt.title(\"Rainfall in Kumasi against Tema\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_mBgyWk4Evh4"
   },
   "source": [
    "Joint Plot\n",
    "----------------------------\n",
    "Seaborn's jointplot draws a plot of two variables with bivariate and univariate graphs. The bivariate plot (bottom left) produces a clustered diagram, which is useful in cluster analysis.\n",
    "\n",
    "> Histograms rather produced an error when this command was originally issued. This may not be same in your case. However, as control, the dataset was formatted to floats by using the astype() method and passing the function float as an argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XVvB4Di645BU"
   },
   "outputs": [],
   "source": [
    "sb.jointplot(x='Tema', y='Kumasi', data=NewRRData.astype(float), kind='hex')\n",
    "plt.suptitle(\"Rainfall in Kumasi against Tema \\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RYRB_0fH4-Jh"
   },
   "source": [
    "Let's replicate the jointplot using monthly rainfall totals. Here, we will utilise the pandas groupby() function, in tandem with the Pandas Grouper class. <br>\n",
    "\n",
    "Grouping Data with Groupby() function\n",
    "----------------------------------------\n",
    "\n",
    "The Pandas groupby() method allows for creating categories or groupings, for groupwise approximations, function applications, etc. <br>\n",
    "\n",
    "eg. <br>\n",
    "> Data.groupby(pd.Grouper(freq='Y')).aggregate(np.sum).plot()  #Annual Total <br>\n",
    "> Data.groupby(pd.Grouper(freq='M')).aggregate(np.sum).plot()  #Monthly Total <br>\n",
    "\n",
    "Alternatively, we can use the resample method (shown below): <br>\n",
    "\n",
    "> Data=Data.astype(float).resample('M').sum()   #Monthly Total <br>\n",
    "> Data=Data.astype(float).resample('Y').sum()   #Annual Total <br>\n",
    "\n",
    "You notice that we utilise the pd.Grouper class. A Grouper allows the user to specify a groupby instruction for an object. This specification will select a column via the key parameter, or if the level and/or axis parameters are given, a level of the index of the target object. If axis and/or level are passed as keywords to both Grouper and groupby, the values passed to Grouper take precedence. In the example above, we pass the frequency as a datetime format (eg. \"Y\" for year, \"M\" for month, \"MS\" for start of month, etc.). This allows for grouping the dataframe into either yearly (first example) or monthly (second example) categories. <br>\n",
    "\n",
    "Thereafter, we employ the aggregate function, while passing as argument, the numpy summation function (np.sum). This produces the summation of each monthly or yearly grouping.<br><br>\n",
    "\n",
    "Okay......... Now, let's replicate the jointplot using monthly rainfall totals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sHUs_Usgs4QL",
    "outputId": "f0ef389c-a1de-49f2-ac40-df1b4c0d3e1b"
   },
   "outputs": [],
   "source": [
    "sb.jointplot(x='Tema', y='Kumasi', data=NewRRData.groupby(pd.Grouper(freq='M')).sum().astype(float), kind='hex')\n",
    "plt.suptitle(\"Rainfall in Kumasi against Tema \\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8u0r2VriE5FL"
   },
   "source": [
    "Pair Plot\n",
    "----------------------------\n",
    "A simple way of identifying relations between each numerical series of a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N2_2KZ_-s4QL",
    "outputId": "e9a566f4-c79f-479e-b7b1-95d85282fbb0"
   },
   "outputs": [],
   "source": [
    "sb.pairplot(NewRRData.groupby(pd.Grouper(freq='M')).sum().astype(float), diag_kind='hist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OuYgsh4wFGON"
   },
   "source": [
    "Quick look into the Timeseries\n",
    "----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YFJCayX1s4QM",
    "outputId": "88ed3a29-84b1-4de0-9779-fd2100f6b123"
   },
   "outputs": [],
   "source": [
    "### Quicklook into the Data\n",
    "cols_plot=stations\n",
    "axes = NewRRData[cols_plot].plot(linestyle='-', figsize=(12, 8), subplots=True)\n",
    "### NewRRData[cols_plot] aids in extracting the Rainfall data to visualize for each station.\n",
    "for ax in axes:\n",
    "    ax.set_ylabel('Rainfall (mm)')\n",
    "    ax.set_ylim(0,150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gC5aU2nes4QO",
    "outputId": "fa14d017-5ddf-41b4-efe8-17f9d8f35610"
   },
   "outputs": [],
   "source": [
    "### Now let's replicate for the daily minimum temperature data.\n",
    "cols_plot=stations\n",
    "axes = NewTNData[cols_plot].plot(linestyle='-', figsize=(12, 8), subplots=True)\n",
    "for ax in axes:\n",
    "    #ax.set_ylabel('Rainfall (mm)')\n",
    "    ax.set_ylabel(r'Temp. ($^o$ C)')\n",
    "    #ax.set_ylim(0,150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WKNDmwEkFShq"
   },
   "source": [
    "Recap:  Grouping Data with Groupby() function\n",
    "----------------------------------------\n",
    "\n",
    "It allows for creating categories or groupings, for groupwise approximations, function applications, etc. <br>\n",
    "\n",
    "eg. <br>\n",
    "Data.groupby(pd.Grouper(freq='Y')).aggregate(np.sum).plot()  #Annual Total <br>\n",
    "Data.groupby(pd.Grouper(freq='M')).aggregate(np.sum).plot()  #Monthly Total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o7qIorZns4QM",
    "outputId": "5bdff13b-ad87-4929-91f1-11cd4ff3cd70"
   },
   "outputs": [],
   "source": [
    "#### Moving Averages\n",
    "Month_Data = NewRRData.groupby(pd.Grouper(freq='M')).aggregate(np.sum)\n",
    "Month_Data.plot()\n",
    "Month_Data.rolling(12).mean().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qRN9UVkEs4QN"
   },
   "source": [
    "\n",
    "Extreme Rainfall Events\n",
    "-------------------------------------------------------------------------------------------------------------------------------\n",
    "- **Rainy Days :** rainfall amount above 1 mm<br />\n",
    "- **Rnnmm (eg. R10mm, R20mm, R50mm) :** events with rainfall amount above 10 mm, 20mm, and 50 mm respectively. <br>\n",
    "- **Percentile** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Y9VleYL86q_"
   },
   "source": [
    "An alternative for identifying elements of a dataframe that meet a specific criteria is to pass the criteria within a square brackets attached to the dataframe. <br>\n",
    "\n",
    "**For example:** <br>\n",
    "> **a[a>1]** implies extracting all **a** elements where the value of **a** exceeds 1.<br><br>\n",
    "\n",
    "We will employ this simplistic indexing method to map out rainy days and rainfall extremes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sTFIVJxks4QN"
   },
   "outputs": [],
   "source": [
    "Rainy_days = Data[Data>=1].groupby(pd.Grouper(freq='M')).count() #Count of Rainy Days\n",
    "R10mm = Data[Data>=10].groupby(pd.Grouper(freq='M')).count() #Count of R10mm events\n",
    "R20mm = Data[Data>=20].groupby(pd.Grouper(freq='M')).count() #Count of R20mm events\n",
    "R50mm = Data[Data>=50].groupby(pd.Grouper(freq='M')).count() #Count of R50mm events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y96Pw5aJAFkH"
   },
   "source": [
    "**Let's quantify the rainfall extremes using the percentile approach**<br>\n",
    "\n",
    "> 1. First, we compute the 95th percentile of the rainfall data using **.quantile(.95)** method. This serves as the threshold for extreme events. \n",
    "> 2. Next, we subtract the 95th percentile rainfall amount from the entire data series.\n",
    "\n",
    "> 3. Afterwards, we employ the .where() method to map out where there is a positive difference (indicating an extreme event), and then ... \n",
    "> 4. we use .count() to quantify the number of these extreme events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wgm_NkZfs4QN"
   },
   "outputs": [],
   "source": [
    "perc=NewRRData['Kumasi'].quantile(.95)   #This produces the 95th percentile value.\n",
    "diff=(NewRRData['Kumasi']-perc)\n",
    "Events_95 = diff.where(diff>0).count()\n",
    "percentage=round((Events_95/diff.count())*100, 3) #Compute the percentage of extreme events in a defined station\n",
    "diff.plot(label='n = '+str(Events_95)+'\\nPercent = '+str(percentage)+'%')\n",
    "plt.axhline(y=0, color='r')\n",
    "plt.legend()\n",
    "plt.title('Events above the Percentile')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dqZ6Yq7kG0Oj"
   },
   "source": [
    "**Trend Assessmet using PyMannKendall**\n",
    "--------------------------------------\n",
    "Pymannkendall (**https://pypi.org/project/pymannkendall/**) allows for trend assessment in a dataset/observation. The package details out numerous sub-packages that are useful for various forms of trend assessment. For simplicity, we will focus on the Mann-Kendall original test. Nonetheless, feel free to try out its numerous trend assessment types after the class. <br> <br><br>\n",
    "\n",
    "**Extra Article:** <br>\n",
    "https://www.researchgate.net/publication/334688255_pyMannKendall_a_python_package_for_non_parametric_Mann_Kendall_family_of_trend_tests <br><br><br>\n",
    "\n",
    "Let's start by importing the PyMannKendall package using <br>\n",
    "> **import *pymannkendall* as *mk***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V1EyFvOps4QO",
    "outputId": "9ba8734e-eba4-4c31-e141-0028fdc639fd"
   },
   "outputs": [],
   "source": [
    "import pymannkendall as mk\n",
    "?mk.original_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wskpnh-cs4QP"
   },
   "outputs": [],
   "source": [
    "#Trends In Data With PyMannKendall\n",
    "mk.original_test(NewRRData['Kumasi'].astype(float))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nu1Xdh-7E7Ei"
   },
   "source": [
    "The output from the above cell provides <br>\n",
    "\n",
    "**Output:**\n",
    ">    trend: tells the trend (increasing, decreasing or no trend)<br>\n",
    ">    h: True (if trend is present) or False (if trend is absence)<br>\n",
    ">    p: p-value of the significance test (eg. P<0.05 implies data is significant at 95% confidence level)  <br>\n",
    ">    z: normalized test statistics <br>\n",
    ">    Tau: Kendall Tau <br>\n",
    ">    s: Mann-Kendal's score <br>\n",
    ">    var_s: Variance S <br>\n",
    ">    slope: sen's slope <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "it52QbB6D0D4"
   },
   "source": [
    "Next, we attempt to produce the slopes for each given station's monthly rainfall totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4xc_89JJs4QP"
   },
   "outputs": [],
   "source": [
    "for station in stations:\n",
    "    print(station,mk.original_test(NewRRData[s].groupby(pd.Grouper(freq='M')).sum().dropna().astype(float)).slope)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I1Cxo3Vqs4QQ"
   },
   "source": [
    "______________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YaysB5rGs4QQ"
   },
   "source": [
    "Tasks / Activity\n",
    "-------------------------------------------------------------------------------------------------------------------------------\n",
    "For the stacked data: <br><br>\n",
    "    1. Compute Monthly and Annual Mean Temperature <br>\n",
    "    2. Identify the trends and magnitude of slope in the computed means in (1).<br>\n",
    "    3. Using seaborn jointplot, let's produce a cluster plot of temperature and rainfall in any of the other locations. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xKXT4aAJs4QQ"
   },
   "outputs": [],
   "source": [
    "Tavg=(NewTNData+NewTXData)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tAlrdZQ9s4QQ"
   },
   "outputs": [],
   "source": [
    "### (1)\n",
    "#Groupby Approach\n",
    "MT_avg=Tavg.astype(float).groupby(pd.Grouper(freq='M')).mean()\n",
    "AT_avg=Tavg.astype(float).groupby(pd.Grouper(freq='Y')).mean()\n",
    "\n",
    "#or\n",
    "#Resample Approach\n",
    "MT_avg=Tavg.astype(float).resample('M').mean()\n",
    "AT_avg=Tavg.astype(float).resample('Y').mean()\n",
    "\n",
    "### (2)\n",
    "Mtrend=mk.original_test(MT_avg['Kumasi'].astype(float))\n",
    "Atrend=mk.original_test(AT_avg['Kumasi'].astype(float))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1lRs9t5Js4QS"
   },
   "outputs": [],
   "source": [
    "### (2)\n",
    "x=MT_avg.apply(standardized_anomaly)\n",
    "y=NewRRData.astype(float).resample('M').sum()\n",
    "\n",
    "h=sb.jointplot(y['Kumasi'],x['Kumasi']), kind='hex')\n",
    "h.set_axis_labels('Temperature', 'Rainfall', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r5PAnlRTs4QS"
   },
   "source": [
    "------------------------------------------------------------------------------------------------------------------------------\n",
    "Tasks / Activity\n",
    "-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    1. Let's produce standardized anomaly plots (formula below) of Daily Mean Temperature and visualize it.\n",
    "    - First, build a function of standardized anomaly. \n",
    "     (You can use the default function build in python or better still, make use of lambda functions.)\n",
    "    - Pass Tavg through the function, and plot out.\n",
    "\n",
    "    NB: Standardized Anomaly (z) = (Ti - mean(T))/standard_deviation (T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mxr_KhIws4QS"
   },
   "outputs": [],
   "source": [
    "### Approach 1\n",
    "def standardized_anomaly(x):\n",
    "    return (x-np.nanmean(x))/np.nanstd(x)\n",
    "\n",
    "standardized_anomaly(Tavg).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dV-Ed0Fms4QT",
    "outputId": "596ad227-7c71-4a00-a299-de901ee91875"
   },
   "outputs": [],
   "source": [
    "#Approach 2\n",
    "standardized_anomaly = lambda x:(x-np.nanmean(x))/np.nanstd(x)\n",
    "Tavg.apply(standardized_anomaly).plot()\n",
    "plt.axhline(y=0, color='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exYrdscTs4QT"
   },
   "source": [
    "______________________________________________________________________________________________________________________________\n",
    "THE END!!!!\n",
    "------------------------------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MZvwgH3Ms4QU"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Pandas_Lecture2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
